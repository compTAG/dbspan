{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e40eef",
   "metadata": {},
   "source": [
    "# Experiments for \"DBSpan: Density-Based Spanner for Clustering Complex Data, With an Application to Persistence Diagrams\"\n",
    "\n",
    "To get started, we will do a little bit of path hackery to import the library.  There are better ways to do this, but for now, this is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d093c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "libpath = os.path.abspath('..')\n",
    "sys.path.insert(0, libpath)\n",
    "\n",
    "import dbspan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82486f89",
   "metadata": {},
   "source": [
    "We will do a bunch of comparisions of DBScan and DBSpan, so it will help if we have some code for making the algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39afd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_metric = dbspan.topology.DiagramMetric()\n",
    "\n",
    "def dgm1_metric(dgm1, dgm2):\n",
    "    return dgm_metric.bottleneck(dgm1[1], dgm2[1])\n",
    "\n",
    "def make_algos(eps, min_samples, delta):\n",
    "    algo_dbscan = dbspan.cluster.DBSCAN(metric=dgm1_metric, eps=eps, min_samples=min_samples)\n",
    "    algo_dbspan = dbspan.cluster.DBSpan(metric=dgm1_metric, eps=eps, min_samples=min_samples, delta=delta)\n",
    "\n",
    "    return algo_dbscan, algo_dbspan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c0c97",
   "metadata": {},
   "source": [
    "## Experiment 1: Point clouds of things in 4D\n",
    "\n",
    "First, we will create some tools for creating dgms of things in 4D.  Each function will produce a diagram from a rips filtration of a \"noisy\" sphere, torus, or swiss roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cc574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factory = dbspan.topology.PointSetDataFactory(seed=72330)\n",
    "dgm_factory = dbspan.topology.DiagramFactory()\n",
    "\n",
    "rng = random.Random(43081)\n",
    "\n",
    "def make_sphere_dgm():\n",
    "    points = data_factory.make_sphere(dim=4, num_points=100, noise=.1)\n",
    "    return dgm_factory.make_from_point_set(points)\n",
    "\n",
    "def make_torus_dgm():\n",
    "    points = data_factory.make_torus(dim=4, num_points=100, noise=.1)\n",
    "    return dgm_factory.make_from_point_set(points)\n",
    "\n",
    "def make_swiss_roll_dgm():\n",
    "    points = data_factory.make_swiss_roll(dim=4, num_points=100, noise=.1)\n",
    "    return dgm_factory.make_from_point_set(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567ad8c",
   "metadata": {},
   "source": [
    "Now that we have some functions for creating data, let's create our data set that we will cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b4ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dgms1 = 30\n",
    "dgms1 = [make_sphere_dgm() for _ in range(num_dgms1)] \\\n",
    "    + [make_torus_dgm() for _ in range(num_dgms1)] \\\n",
    "    + [make_swiss_roll_dgm() for _ in range(math.floor(num_dgms1/2) - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efd5c7",
   "metadata": {},
   "source": [
    "And we are off!  Let's do some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d931b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def make_cache(true_labels, dbscan_time):\n",
    "    return {\n",
    "        'true_labels': true_labels,\n",
    "        'dbscan_time': dbscan_time,\n",
    "    }  \n",
    "    \n",
    "def run_experiment1(df, data, delta, eps, min_samples, cache=None):\n",
    "    \n",
    "    def add_row(df, delta, num_edges, max_edges, rand_index, dbscan_time, dbspan_time):\n",
    "        data = [delta, rand_index, num_edges, max_edges, num_edges/max_edges, dbscan_time, dbspan_time, dbscan_time/dbspan_time]\n",
    "        cols=['$\\delta$', 'Rand index', 'Num Edges', 'maxEdges', '\\% Possible Edges', 'T_DBSCAN', 'DBSpan time (sec)', 'Speedup']\n",
    "        line = pd.DataFrame([data,], columns=cols)\n",
    "        return pd.concat([df, line])\n",
    "   \n",
    "    # create the algos\n",
    "    algo_dbscan, algo_dbspan = make_algos(eps=eps, min_samples=min_samples, delta=delta)\n",
    "\n",
    "    # run the algos\n",
    "    t0 = time.perf_counter()\n",
    "    true_labels = cache['true_labels'] if cache else algo_dbscan.fit(data)\n",
    "    t1 = time.perf_counter()\n",
    "    dbspan_labels, dbg_data= algo_dbspan.fit(data, dbg=True)\n",
    "    t2 = time.perf_counter()\n",
    "    \n",
    "    # pull out the dbg data for the analysis\n",
    "    spanner = dbg_data['neighborhood'].spanner\n",
    "    \n",
    "    # prepare data for row\n",
    "    rand_index = metrics.adjusted_rand_score(true_labels, dbspan_labels)\n",
    "    dbscan_time = cache['dbscan_time'] if cache else t1 - t0\n",
    "    dbspan_time = t2 - t1\n",
    "    num_edges = spanner.number_of_edges()\n",
    "    n = spanner.number_of_nodes()\n",
    "    max_edges = n * (n-1) / 2\n",
    "    \n",
    "    # return row\n",
    "    return add_row(df, delta, num_edges, max_edges, rand_index, dbscan_time, dbspan_time), \\\n",
    "        make_cache(true_labels, dbscan_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6668efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1         1.0       2256    2701.0           0.835246  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1         1.0       2256    2701.0           0.835246  73.043168   \n",
      "0       1.0         1.0       1137    2701.0           0.420955  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "0          45.429457  1.607837  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1         1.0       2256    2701.0           0.835246  73.043168   \n",
      "0       1.0         1.0       1137    2701.0           0.420955  73.043168   \n",
      "0      10.0         1.0        475    2701.0           0.175861  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "0          45.429457  1.607837  \n",
      "0          19.385153  3.767995  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1    1.000000       2256    2701.0           0.835246  73.043168   \n",
      "0       1.0    1.000000       1137    2701.0           0.420955  73.043168   \n",
      "0      10.0    1.000000        475    2701.0           0.175861  73.043168   \n",
      "0      50.0    0.671534        387    2701.0           0.143280  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "0          45.429457  1.607837  \n",
      "0          19.385153  3.767995  \n",
      "0          15.458185  4.725210  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1    1.000000       2256    2701.0           0.835246  73.043168   \n",
      "0       1.0    1.000000       1137    2701.0           0.420955  73.043168   \n",
      "0      10.0    1.000000        475    2701.0           0.175861  73.043168   \n",
      "0      50.0    0.671534        387    2701.0           0.143280  73.043168   \n",
      "0     100.0    0.869315        374    2701.0           0.138467  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "0          45.429457  1.607837  \n",
      "0          19.385153  3.767995  \n",
      "0          15.458185  4.725210  \n",
      "0          14.680852  4.975404  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1    1.000000       2256    2701.0           0.835246  73.043168   \n",
      "0       1.0    1.000000       1137    2701.0           0.420955  73.043168   \n",
      "0      10.0    1.000000        475    2701.0           0.175861  73.043168   \n",
      "0      50.0    0.671534        387    2701.0           0.143280  73.043168   \n",
      "0     100.0    0.869315        374    2701.0           0.138467  73.043168   \n",
      "0     500.0    0.658561        378    2701.0           0.139948  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "0          45.429457  1.607837  \n",
      "0          19.385153  3.767995  \n",
      "0          15.458185  4.725210  \n",
      "0          14.680852  4.975404  \n",
      "0          15.192167  4.807949  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges   T_DBSCAN  \\\n",
      "0       0.1    1.000000       2256    2701.0           0.835246  73.043168   \n",
      "0       1.0    1.000000       1137    2701.0           0.420955  73.043168   \n",
      "0      10.0    1.000000        475    2701.0           0.175861  73.043168   \n",
      "0      50.0    0.671534        387    2701.0           0.143280  73.043168   \n",
      "0     100.0    0.869315        374    2701.0           0.138467  73.043168   \n",
      "0     500.0    0.658561        378    2701.0           0.139948  73.043168   \n",
      "0    1000.0    0.931712        373    2701.0           0.138097  73.043168   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0          79.664465  0.916885  \n",
      "0          45.429457  1.607837  \n",
      "0          19.385153  3.767995  \n",
      "0          15.458185  4.725210  \n",
      "0          14.680852  4.975404  \n",
      "0          15.192167  4.807949  \n",
      "0          14.802099  4.934649  \n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      " & $\\delta$ & Rand index & Num Edges & maxEdges & \\% Possible Edges & T_DBSCAN & DBSpan time (sec) & Speedup \\\\\n",
      "0 & 0.100000 & 1.000000 & 2256 & 2701.000000 & 0.835246 & 73.043168 & 79.664465 & 0.916885 \\\\\n",
      "0 & 1.000000 & 1.000000 & 1137 & 2701.000000 & 0.420955 & 73.043168 & 45.429457 & 1.607837 \\\\\n",
      "0 & 10.000000 & 1.000000 & 475 & 2701.000000 & 0.175861 & 73.043168 & 19.385153 & 3.767995 \\\\\n",
      "0 & 50.000000 & 0.671534 & 387 & 2701.000000 & 0.143280 & 73.043168 & 15.458185 & 4.725210 \\\\\n",
      "0 & 100.000000 & 0.869315 & 374 & 2701.000000 & 0.138467 & 73.043168 & 14.680852 & 4.975404 \\\\\n",
      "0 & 500.000000 & 0.658561 & 378 & 2701.000000 & 0.139948 & 73.043168 & 15.192167 & 4.807949 \\\\\n",
      "0 & 1000.000000 & 0.931712 & 373 & 2701.000000 & 0.138097 & 73.043168 & 14.802099 & 4.934649 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results1 = None\n",
    "cache1 = None\n",
    "eps1 = .3\n",
    "min_samples1 = 15\n",
    "for delta in [.1, 1, 10, 50, 100, 500, 1000]:\n",
    "    results1, cache1 = run_experiment1(results1, dgms1, delta, eps1, min_samples1, cache=cache1)\n",
    "    print(results1)\n",
    "\n",
    "print(results1.style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f9da1",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b96dfc",
   "metadata": {},
   "source": [
    "First, we will load in the data.  Since it is pretty small when gzipped, we keep it in the repo.  Let's unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d4ad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   459  100   459    0     0   1473      0 --:--:-- --:--:-- --:--:--  1509\n",
      "100 10.3M  100 10.3M    0     0  2520k      0  0:00:04  0:00:04 --:--:-- 3949k\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!curl -J -L https://osf.io/4nwe9/download | tar xz --directory data\n",
    "!echo \"done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03aecee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 8595 dgms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "exp2_data_dir = './data/experiment2/'\n",
    "exp2_files = os.listdir(exp2_data_dir)\n",
    "\n",
    "def read_file(name):\n",
    "    file_name = os.path.join(exp2_data_dir, name)\n",
    "    return [None, np.genfromtxt(file_name, delimiter=',')]\n",
    "\n",
    "dgms2 = [ read_file(name) for name in exp2_files ]\n",
    "print(\"Read in {} dgms\".format(len(dgms2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b78d6e",
   "metadata": {},
   "source": [
    "Next, let's look at the distribution of the number of points in the diagrams.  Personally, I don't know much about this data set, but MSU local expert (and super well guy that gave me these diagrams) Jordan Schupbach said that number of diagram points could be a useful to look at.  So let's look at the distribution of of the number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed32fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5941., 1750.,  560.,  190.,   53.,   40.,   29.,   15.,   11.,\n",
       "           6.]),\n",
       " array([101. , 125.9, 150.8, 175.7, 200.6, 225.5, 250.4, 275.3, 300.2,\n",
       "        325.1, 350. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASH0lEQVR4nO3df6zd9V3H8edLytji5grj2pC2s9U1Lsw4RiqwaIyOCIUZiwlbMMY1S5MmysxMNFo0Ed2GYSYOJXEsOLqVOWXIttBsU6wFs/gHP8pgDOiwVzZCm0LrCuhcRNne/nE+l53Ve3vPbc89d72f5yM5Od/v+/s53/N953v7Ot/zPd9zmqpCktSHH1jqDZAkTY6hL0kdMfQlqSOGviR1xNCXpI6sWOoNOJ6zzz671q1bt9SbIUmnlAcffPDfq2pqtmXf16G/bt069u7du9SbIUmnlCRPzbXM0zuS1BFDX5I6YuhLUkdGCv0kK5PckeSrSfYleWuSs5LsTrK/3Z/ZxibJjUmmkzyS5Pyh9Wxp4/cn2bJYTUmSZjfqkf5fAP9QVW8E3gzsA7YDe6pqA7CnzQNcBmxot23ATQBJzgKuBS4ELgCunXmhkCRNxryhn+S1wM8CtwBU1f9U1fPAZmBnG7YTuKJNbwZurYF7gZVJzgEuBXZX1dGqeg7YDWwaYy+SpHmMcqS/HjgCfCzJQ0k+muQHgVVVdaiNeQZY1aZXA08PPf5Aq81VlyRNyCihvwI4H7ipqt4C/BffPZUDQA1+n3ksv9GcZFuSvUn2HjlyZByrlCQ1o4T+AeBAVd3X5u9g8CLwbDttQ7s/3JYfBNYOPX5Nq81V/x5VdXNVbayqjVNTs36hTJJ0gub9Rm5VPZPk6SQ/XlVPABcDj7fbFuD6dn9ne8gu4D1JbmPwoe0LVXUoyV3Anwx9eHsJcM142/le67Z/fjFXP6evX//2JXleSZrPqD/D8JvAJ5O8AngSeDeDdwm3J9kKPAW8s439AnA5MA18q42lqo4meT/wQBv3vqo6OpYuJEkjGSn0q+phYOMsiy6eZWwBV8+xnh3AjgVsnyRpjPxGriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6MFPpJvp7kK0keTrK31c5KsjvJ/nZ/ZqsnyY1JppM8kuT8ofVsaeP3J9myOC1JkuaykCP9n6+q86pqY5vfDuypqg3AnjYPcBmwod22ATfB4EUCuBa4ELgAuHbmhUKSNBknc3pnM7CzTe8Erhiq31oD9wIrk5wDXArsrqqjVfUcsBvYdBLPL0laoFFDv4B/TPJgkm2ttqqqDrXpZ4BVbXo18PTQYw+02lx1SdKErBhx3M9U1cEkPwzsTvLV4YVVVUlqHBvUXlS2Abz+9a8fxyolSc1IR/pVdbDdHwY+y+Cc/LPttA3t/nAbfhBYO/TwNa02V/3Y57q5qjZW1capqamFdSNJOq55Qz/JDyZ5zcw0cAnwKLALmLkCZwtwZ5veBbyrXcVzEfBCOw10F3BJkjPbB7iXtJokaUJGOb2zCvhskpnxf1NV/5DkAeD2JFuBp4B3tvFfAC4HpoFvAe8GqKqjSd4PPNDGva+qjo6tE0nSvOYN/ap6EnjzLPVvABfPUi/g6jnWtQPYsfDNlCSNg9/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGRQz/JaUkeSvK5Nr8+yX1JppN8KskrWv2MNj/dlq8bWsc1rf5EkkvH3o0k6bgWcqT/XmDf0PwHgRuq6g3Ac8DWVt8KPNfqN7RxJDkXuAp4E7AJ+HCS005u8yVJCzFS6CdZA7wd+GibD/A24I42ZCdwRZve3OZpyy9u4zcDt1XVi1X1NWAauGAMPUiSRjTqkf6fA78LfKfNvw54vqpeavMHgNVtejXwNEBb/kIb/3J9lse8LMm2JHuT7D1y5MjonUiS5jVv6Cf5ReBwVT04ge2hqm6uqo1VtXFqamoSTylJ3VgxwpifBn4pyeXAK4EfAv4CWJlkRTuaXwMcbOMPAmuBA0lWAK8FvjFUnzH8GEnSBMx7pF9V11TVmqpax+CD2Lur6leBe4Ar27AtwJ1telebpy2/u6qq1a9qV/esBzYA94+tE0nSvEY50p/L7wG3JfkA8BBwS6vfAnwiyTRwlMELBVX1WJLbgceBl4Crq+rbJ/H8kqQFWlDoV9U/A//cpp9klqtvquq/gXfM8fjrgOsWupGSpPHwG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Mm/oJ3llkvuTfDnJY0n+uNXXJ7kvyXSSTyV5Rauf0ean2/J1Q+u6ptWfSHLponUlSZrVKEf6LwJvq6o3A+cBm5JcBHwQuKGq3gA8B2xt47cCz7X6DW0cSc4FrgLeBGwCPpzktDH2Ikmax7yhXwPfbLOnt1sBbwPuaPWdwBVtenObpy2/OEla/baqerGqvgZMAxeMowlJ0mhGOqef5LQkDwOHgd3AvwHPV9VLbcgBYHWbXg08DdCWvwC8brg+y2OGn2tbkr1J9h45cmTBDUmS5jZS6FfVt6vqPGANg6PzNy7WBlXVzVW1sao2Tk1NLdbTSFKXFnT1TlU9D9wDvBVYmWRFW7QGONimDwJrAdry1wLfGK7P8hhJ0gSMcvXOVJKVbfpVwC8A+xiE/5Vt2Bbgzja9q83Tlt9dVdXqV7Wre9YDG4D7x9SHJGkEK+YfwjnAznalzQ8At1fV55I8DtyW5APAQ8AtbfwtwCeSTANHGVyxQ1U9luR24HHgJeDqqvr2eNuRJB3PvKFfVY8Ab5ml/iSzXH1TVf8NvGOOdV0HXLfwzZQkjYPfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSReUM/ydok9yR5PMljSd7b6mcl2Z1kf7s/s9WT5MYk00keSXL+0Lq2tPH7k2xZvLYkSbMZ5Uj/JeC3q+pc4CLg6iTnAtuBPVW1AdjT5gEuAza02zbgJhi8SADXAhcCFwDXzrxQSJImY97Qr6pDVfWlNv2fwD5gNbAZ2NmG7QSuaNObgVtr4F5gZZJzgEuB3VV1tKqeA3YDm8bZjCTp+BZ0Tj/JOuAtwH3Aqqo61BY9A6xq06uBp4cedqDV5qof+xzbkuxNsvfIkSML2TxJ0jxGDv0krwY+DfxWVf3H8LKqKqDGsUFVdXNVbayqjVNTU+NYpSSpGSn0k5zOIPA/WVWfaeVn22kb2v3hVj8IrB16+JpWm6suSZqQUa7eCXALsK+qPjS0aBcwcwXOFuDOofq72lU8FwEvtNNAdwGXJDmzfYB7SatJkiZkxQhjfhr4NeArSR5utd8HrgduT7IVeAp4Z1v2BeByYBr4FvBugKo6muT9wANt3Puq6ug4mpAkjWbe0K+qfwEyx+KLZxlfwNVzrGsHsGMhGyhJGh+/kStJHTH0Jakjhr4kdWSUD3K1QOu2f35Jnvfr1799SZ5X0qnDI31J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSReUM/yY4kh5M8OlQ7K8nuJPvb/ZmtniQ3JplO8kiS84ces6WN359ky+K0I0k6nlGO9D8ObDqmth3YU1UbgD1tHuAyYEO7bQNugsGLBHAtcCFwAXDtzAuFJGly5g39qvoicPSY8mZgZ5veCVwxVL+1Bu4FViY5B7gU2F1VR6vqOWA3//+FRJK0yE70nP6qqjrUpp8BVrXp1cDTQ+MOtNpc9f8nybYke5PsPXLkyAluniRpNif9QW5VFVBj2JaZ9d1cVRurauPU1NS4VitJ4sRD/9l22oZ2f7jVDwJrh8atabW56pKkCTrR0N8FzFyBswW4c6j+rnYVz0XAC+000F3AJUnObB/gXtJqkqQJWjHfgCR/C/wccHaSAwyuwrkeuD3JVuAp4J1t+BeAy4Fp4FvAuwGq6miS9wMPtHHvq6pjPxyWJC2yeUO/qn5ljkUXzzK2gKvnWM8OYMeCtk6SNFZ+I1eSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoy7zdydepYt/3zS/bcX7/+7Uv23JJG55G+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjriD65pLJbqx978oTdpYTzSl6SOGPqS1BFDX5I6MvHQT7IpyRNJppNsn/TzS1LPJvpBbpLTgL8EfgE4ADyQZFdVPT7J7dDysZT/W9hS8cNrnYxJX71zATBdVU8CJLkN2AwY+tKIenyhWyrL8QV20qG/Gnh6aP4AcOHwgCTbgG1t9ptJnjiB5zkb+PcT2sJTV489Q5992/OE5IOTfsbvcTI9/8hcC77vrtOvqpuBm09mHUn2VtXGMW3SKaHHnqHPvu25D4vV86Q/yD0IrB2aX9NqkqQJmHToPwBsSLI+ySuAq4BdE94GSerWRE/vVNVLSd4D3AWcBuyoqscW4alO6vTQKarHnqHPvu25D4vSc6pqMdYrSfo+5DdyJakjhr4kdeSUDP0kO5IcTvLoUO2sJLuT7G/3Z7Z6ktzYfvbhkSTnL92Wn7g5ev6jJAeTPNxulw8tu6b1/ESSS5dmq09OkrVJ7knyeJLHkry31Zftvj5Oz8t2Xyd5ZZL7k3y59fzHrb4+yX2tt0+1iz9Ickabn27L1y1pAyfgOD1/PMnXhvbzea0+vr/tqjrlbsDPAucDjw7V/hTY3qa3Ax9s05cDfw8EuAi4b6m3f4w9/xHwO7OMPRf4MnAGsB74N+C0pe7hBHo+Bzi/Tb8G+NfW27Ld18fpednu67a/Xt2mTwfua/vvduCqVv8I8Ott+jeAj7Tpq4BPLXUPY+z548CVs4wf29/2KXmkX1VfBI4eU94M7GzTO4Erhuq31sC9wMok50xkQ8dojp7nshm4raperKqvAdMMfgLjlFJVh6rqS236P4F9DL7VvWz39XF6nsspv6/b/vpmmz293Qp4G3BHqx+7n2f2/x3AxUkyma0dj+P0PJex/W2fkqE/h1VVdahNPwOsatOz/fTD8f4RnWre097u7Zg5zcEy7Lm9hX8LgyOiLvb1MT3DMt7XSU5L8jBwGNjN4B3L81X1Uhsy3NfLPbflLwCvm+gGj8GxPVfVzH6+ru3nG5Kc0Wpj28/LKfRfVoP3Qz1ci3oT8GPAecAh4M+WdGsWSZJXA58Gfquq/mN42XLd17P0vKz3dVV9u6rOY/At/QuANy7tFi2+Y3tO8hPANQx6/yngLOD3xv28yyn0n515u9PuD7f6sv3ph6p6tv3hfAf4K777tn7Z9JzkdAbh98mq+kwrL+t9PVvPPexrgKp6HrgHeCuDUxgzXyAd7uvlntvy1wLfmOyWjs9Qz5va6b2qqheBj7EI+3k5hf4uYEub3gLcOVR/V/v0+yLghaFTA6e0Y87p/TIwc2XPLuCqdpXDemADcP+kt+9ktfO0twD7qupDQ4uW7b6eq+flvK+TTCVZ2aZfxeD/29jHIAivbMOO3c8z+/9K4O72ju+UMUfPXx06mAmDzzCG9/N4/raX+lPsE7kBf8vgLe7/Mji3tZXBOb09wH7gn4Cz6rufkv8lg3OEXwE2LvX2j7HnT7SeHml/FOcMjf+D1vMTwGVLvf0n2PPPMDh18wjwcLtdvpz39XF6Xrb7GvhJ4KHW26PAH7b6jzJ4AZsG/g44o9Vf2ean2/IfXeoextjz3W0/Pwr8Nd+9wmdsf9v+DIMkdWQ5nd6RJM3D0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kd+T9WLZVfUqdEJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "npts = np.array([dgm[1].shape[0] for dgm in dgms2])\n",
    "plt.hist(npts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb8ab5",
   "metadata": {},
   "source": [
    "So, it looks like we have a bunch of smallish dgms and a few very large diagrams.  To get a good distribution of diagram sizes, we will create three levels each containing the same number of diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7f3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms_by_level = [\n",
    "    np.argwhere(npts < 150),\n",
    "    np.argwhere((150 <= npts) & (npts < 200)),\n",
    "    np.argwhere(200 <= npts),\n",
    "]\n",
    "\n",
    "def make_data2(dgms_per_level):\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    return [\n",
    "        dgms2[idx]\n",
    "        for level in dgms_by_level\n",
    "        for idx in rng.choice(level.transpose()[0], size=dgms_per_level, replace=False)\n",
    "    ]\n",
    "\n",
    "small_data2 = make_data2(dgms_per_level=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed5816",
   "metadata": {},
   "source": [
    "Next, let's look at the pairwise distance matrix of a very small dataset.  (Note that the code below takes quite a while to run and stare at to pick some constants.  Uncomment to check out the distances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe2aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(small_data2)):\n",
    "#     for j in range(i+1, len(small_data2)):\n",
    "#         print(i, j, dgm1_metric(small_data2[i], small_data2[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e22801",
   "metadata": {},
   "source": [
    "So, it looks like we have a bunch of close diagrams all with distance less than 10 and then some outliers.  So, let's cluster our points using and epsilon of 10 and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ab778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_labels': array([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1]), 'dbscan_time': 279.8122000420699}\n"
     ]
    }
   ],
   "source": [
    "eps2 = 10\n",
    "min_samples2 = 5\n",
    "\n",
    "algo_dbscan = dbspan.cluster.DBSCAN(metric=dgm1_metric, eps=eps2, min_samples=min_samples2)\n",
    "\n",
    "# run the algos\n",
    "t0 = time.perf_counter()\n",
    "true_labels = algo_dbscan.fit(small_data2)\n",
    "t1 = time.perf_counter()\n",
    "dbscan_time = t1-t0\n",
    "cache2 = make_cache(true_labels, dbscan_time)\n",
    "print(cache2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461019c6",
   "metadata": {},
   "source": [
    "So, as we expected, we have a one cluster of diagrams and some noise.  Now, let's run the same experiments that we ran before to pick a good value for delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e73880b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1         1.0        435     435.0                1.0  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1    1.000000        435     435.0           1.000000  279.8122   \n",
      "0       1.0    0.866529        282     435.0           0.648276  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "0         181.501554  1.541652  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1    1.000000        435     435.0           1.000000  279.8122   \n",
      "0       1.0    0.866529        282     435.0           0.648276  279.8122   \n",
      "0       2.0    0.627675        208     435.0           0.478161  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "0         181.501554  1.541652  \n",
      "0         138.057328  2.026783  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1    1.000000        435     435.0           1.000000  279.8122   \n",
      "0       1.0    0.866529        282     435.0           0.648276  279.8122   \n",
      "0       2.0    0.627675        208     435.0           0.478161  279.8122   \n",
      "0       3.0    0.522483        177     435.0           0.406897  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "0         181.501554  1.541652  \n",
      "0         138.057328  2.026783  \n",
      "0         116.465237  2.402538  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1    1.000000        435     435.0           1.000000  279.8122   \n",
      "0       1.0    0.866529        282     435.0           0.648276  279.8122   \n",
      "0       2.0    0.627675        208     435.0           0.478161  279.8122   \n",
      "0       3.0    0.522483        177     435.0           0.406897  279.8122   \n",
      "0       4.0    0.627675        159     435.0           0.365517  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "0         181.501554  1.541652  \n",
      "0         138.057328  2.026783  \n",
      "0         116.465237  2.402538  \n",
      "0         106.308731  2.632072  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1    1.000000        435     435.0           1.000000  279.8122   \n",
      "0       1.0    0.866529        282     435.0           0.648276  279.8122   \n",
      "0       2.0    0.627675        208     435.0           0.478161  279.8122   \n",
      "0       3.0    0.522483        177     435.0           0.406897  279.8122   \n",
      "0       4.0    0.627675        159     435.0           0.365517  279.8122   \n",
      "0       5.0    0.522483        149     435.0           0.342529  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "0         181.501554  1.541652  \n",
      "0         138.057328  2.026783  \n",
      "0         116.465237  2.402538  \n",
      "0         106.308731  2.632072  \n",
      "0         102.356569  2.733700  \n",
      "   $\\delta$  Rand index  Num Edges  maxEdges  \\% Possible Edges  T_DBSCAN  \\\n",
      "0       0.1    1.000000        435     435.0           1.000000  279.8122   \n",
      "0       1.0    0.866529        282     435.0           0.648276  279.8122   \n",
      "0       2.0    0.627675        208     435.0           0.478161  279.8122   \n",
      "0       3.0    0.522483        177     435.0           0.406897  279.8122   \n",
      "0       4.0    0.627675        159     435.0           0.365517  279.8122   \n",
      "0       5.0    0.522483        149     435.0           0.342529  279.8122   \n",
      "0       6.0    0.742386        143     435.0           0.328736  279.8122   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         286.322397  0.977263  \n",
      "0         181.501554  1.541652  \n",
      "0         138.057328  2.026783  \n",
      "0         116.465237  2.402538  \n",
      "0         106.308731  2.632072  \n",
      "0         102.356569  2.733700  \n",
      "0          95.204574  2.939063  \n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      " & $\\delta$ & Rand index & Num Edges & maxEdges & \\% Possible Edges & T_DBSCAN & DBSpan time (sec) & Speedup \\\\\n",
      "0 & 0.100000 & 1.000000 & 435 & 435.000000 & 1.000000 & 279.812200 & 286.322397 & 0.977263 \\\\\n",
      "0 & 1.000000 & 0.866529 & 282 & 435.000000 & 0.648276 & 279.812200 & 181.501554 & 1.541652 \\\\\n",
      "0 & 2.000000 & 0.627675 & 208 & 435.000000 & 0.478161 & 279.812200 & 138.057328 & 2.026783 \\\\\n",
      "0 & 3.000000 & 0.522483 & 177 & 435.000000 & 0.406897 & 279.812200 & 116.465237 & 2.402538 \\\\\n",
      "0 & 4.000000 & 0.627675 & 159 & 435.000000 & 0.365517 & 279.812200 & 106.308731 & 2.632072 \\\\\n",
      "0 & 5.000000 & 0.522483 & 149 & 435.000000 & 0.342529 & 279.812200 & 102.356569 & 2.733700 \\\\\n",
      "0 & 6.000000 & 0.742386 & 143 & 435.000000 & 0.328736 & 279.812200 & 95.204574 & 2.939063 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = None\n",
    "for delta in [.1, 1, 2, 3, 4, 5, 6]:\n",
    "    results2, cache2 = run_experiment1(results2, small_data2, delta, eps2, min_samples2, cache=cache2)\n",
    "    print(results2)\n",
    "print(results2.style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ee83a",
   "metadata": {},
   "source": [
    "Excellent!!  So what did we learn, well, we can get a pretty good speed up and maintain pretty good accuracy if we pick delta just before the rand index dropps off.  Now let's see how large of a data set we can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af78462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:57:48 INFO     (30, 185.1409450409701, 285, 435.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges    T_DBSCAN  \\\n",
      "0        30         1.0        285     435.0           0.655172  283.248509   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:09:41 INFO     (45, 429.65287029207684, 656, 990.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges    T_DBSCAN  \\\n",
      "0        30         1.0        285     435.0           0.655172  283.248509   \n",
      "0        45         1.0        656     990.0           0.662626  654.448212   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n",
      "0         429.652870  1.523202  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:59:52 INFO     (60, 656.3668717920082, 1141, 1770.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges     T_DBSCAN  \\\n",
      "0        30    1.000000        285     435.0           0.655172   283.248509   \n",
      "0        45    1.000000        656     990.0           0.662626   654.448212   \n",
      "0        60    0.793718       1141    1770.0           0.644633  1007.534399   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n",
      "0         429.652870  1.523202  \n",
      "0         656.366872  1.535017  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 02:20:49 INFO     (75, 998.3531174999662, 1525, 2775.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges     T_DBSCAN  \\\n",
      "0        30    1.000000        285     435.0           0.655172   283.248509   \n",
      "0        45    1.000000        656     990.0           0.662626   654.448212   \n",
      "0        60    0.793718       1141    1770.0           0.644633  1007.534399   \n",
      "0        75    0.941231       1525    2775.0           0.549550  1762.891531   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n",
      "0         429.652870  1.523202  \n",
      "0         656.366872  1.535017  \n",
      "0         998.353117  1.765800  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 04:32:22 INFO     (90, 1369.5764904579846, 2250, 4005.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges     T_DBSCAN  \\\n",
      "0        30    1.000000        285     435.0           0.655172   283.248509   \n",
      "0        45    1.000000        656     990.0           0.662626   654.448212   \n",
      "0        60    0.793718       1141    1770.0           0.644633  1007.534399   \n",
      "0        75    0.941231       1525    2775.0           0.549550  1762.891531   \n",
      "0        90    0.901672       2250    4005.0           0.561798  2435.761776   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n",
      "0         429.652870  1.523202  \n",
      "0         656.366872  1.535017  \n",
      "0         998.353117  1.765800  \n",
      "0        1369.576490  1.778478  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 06:31:02 INFO     (105, 1942.8771660840139, 2964, 5460.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges     T_DBSCAN  \\\n",
      "0        30    1.000000        285     435.0           0.655172   283.248509   \n",
      "0        45    1.000000        656     990.0           0.662626   654.448212   \n",
      "0        60    0.793718       1141    1770.0           0.644633  1007.534399   \n",
      "0        75    0.941231       1525    2775.0           0.549550  1762.891531   \n",
      "0        90    0.901672       2250    4005.0           0.561798  2435.761776   \n",
      "0       105    0.958183       2964    5460.0           0.542857  3476.131299   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n",
      "0         429.652870  1.523202  \n",
      "0         656.366872  1.535017  \n",
      "0         998.353117  1.765800  \n",
      "0        1369.576490  1.778478  \n",
      "0        1942.877166  1.789167  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 09:06:51 INFO     (120, 2269.6275037919404, 3523, 7140.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Dgms  Rand index  Num Edges  maxEdges  \\% Possible Edges     T_DBSCAN  \\\n",
      "0        30    1.000000        285     435.0           0.655172   283.248509   \n",
      "0        45    1.000000        656     990.0           0.662626   654.448212   \n",
      "0        60    0.793718       1141    1770.0           0.644633  1007.534399   \n",
      "0        75    0.941231       1525    2775.0           0.549550  1762.891531   \n",
      "0        90    0.901672       2250    4005.0           0.561798  2435.761776   \n",
      "0       105    0.958183       2964    5460.0           0.542857  3476.131299   \n",
      "0       120    0.857597       3523    7140.0           0.493417  4457.904083   \n",
      "\n",
      "   DBSpan time (sec)   Speedup  \n",
      "0         185.140945  1.529907  \n",
      "0         429.652870  1.523202  \n",
      "0         656.366872  1.535017  \n",
      "0         998.353117  1.765800  \n",
      "0        1369.576490  1.778478  \n",
      "0        1942.877166  1.789167  \n",
      "0        2269.627504  1.964157  \n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      " & Num Dgms & Rand index & Num Edges & maxEdges & \\% Possible Edges & T_DBSCAN & DBSpan time (sec) & Speedup \\\\\n",
      "0 & 30 & 1.000000 & 285 & 435.000000 & 0.655172 & 283.248509 & 185.140945 & 1.529907 \\\\\n",
      "0 & 45 & 1.000000 & 656 & 990.000000 & 0.662626 & 654.448212 & 429.652870 & 1.523202 \\\\\n",
      "0 & 60 & 0.793718 & 1141 & 1770.000000 & 0.644633 & 1007.534399 & 656.366872 & 1.535017 \\\\\n",
      "0 & 75 & 0.941231 & 1525 & 2775.000000 & 0.549550 & 1762.891531 & 998.353117 & 1.765800 \\\\\n",
      "0 & 90 & 0.901672 & 2250 & 4005.000000 & 0.561798 & 2435.761776 & 1369.576490 & 1.778478 \\\\\n",
      "0 & 105 & 0.958183 & 2964 & 5460.000000 & 0.542857 & 3476.131299 & 1942.877166 & 1.789167 \\\\\n",
      "0 & 120 & 0.857597 & 3523 & 7140.000000 & 0.493417 & 4457.904083 & 2269.627504 & 1.964157 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta2 = 1\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def run_experiment2(df, num_per_level, delta, eps, min_samples):\n",
    "  \n",
    "    def add_row(df, num_dgms, num_edges, max_edges, rand_index, dbscan_time, dbspan_time):\n",
    "        data = [num_dgms, rand_index, num_edges, max_edges, num_edges/max_edges, dbscan_time, dbspan_time, dbscan_time/dbspan_time]\n",
    "        cols=['Num Dgms', 'Rand index', 'Num Edges', 'maxEdges', '\\% Possible Edges', 'T_DBSCAN', 'DBSpan time (sec)', 'Speedup']\n",
    "        line = pd.DataFrame([data,], columns=cols)\n",
    "        return pd.concat([df, line])\n",
    "  \n",
    "    d2 = make_data2(dgms_per_level=num_per_level)\n",
    "    \n",
    "    algo_dbscan, algo_dbspan = make_algos(eps=eps, min_samples=min_samples, delta=delta)\n",
    "\n",
    "    # run the algos\n",
    "    t0 = time.perf_counter()\n",
    "    dbspan_labels, dbg_data= algo_dbspan.fit(d2, dbg=True)\n",
    "    dbspan_time = time.perf_counter() - t0\n",
    "\n",
    "    # prep dbspan data\n",
    "    spanner = dbg_data['neighborhood'].spanner    \n",
    "    num_edges = spanner.number_of_edges()\n",
    "    n = spanner.number_of_nodes()\n",
    "    max_edges = n * (n-1) / 2\n",
    "    \n",
    "    logging.info((n, dbspan_time, num_edges, max_edges))\n",
    "    \n",
    "    # run dbscan\n",
    "    t1 = time.perf_counter()\n",
    "    true_labels = algo_dbscan.fit(d2)\n",
    "    dbscan_time = time.perf_counter() - t1\n",
    "    \n",
    "    # prepare data for row\n",
    "    rand_index = metrics.adjusted_rand_score(true_labels, dbspan_labels)   \n",
    "\n",
    "    # return row\n",
    "    return add_row(df, n, num_edges, max_edges, rand_index, dbscan_time, dbspan_time)\n",
    "    \n",
    "results2b = None\n",
    "eps2 = 10\n",
    "min_samples2 = 5\n",
    "for i in [10, 15, 20, 25, 30, 35, 40]:\n",
    "    results2b = run_experiment2(results2b, i, delta2, eps2, min_samples2)\n",
    "    print(results2b)\n",
    "\n",
    "print(results2b.style.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
